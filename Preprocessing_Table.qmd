---
title: "Effect Size Preprocessing Table"
format: pdf
editor: visual
author: "Author"
date: "2023-08-08"
date-format: iso
---

```{r}
#| warning: false
#| message: false
#| include: false
#| label: setup
## Load required packages
library(mosaic)
library(tidyverse)
library(knitr)
library(kableExtra)
library(tidyr)
library(Stat2Data)
library(dplyr)
library(meta)
library(metafor)
library(dmetar)
library(metaDigitise)
library(ICC)
library(wildmeta)
library(future)
library(shinyDigitise)
library(CircStats)
library(Directional)
options(digits = 4)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "",
                      tidy=FALSE, size="small")
```

```{r}
#| warning: false
#| message: false
#| include: false
## All papers that provided source data and/or reported correlation in graphs
## have undergone preprocess to normalize the correlation coefficient
## After preprocessing in R, all correlation coefficients reported as pearson's
## r were transformed to Fisher's z by the Practical Meta-Analysis Effect Size 
## Calculator developed by Dr.Wilson
```

```{r}
#| include: false
## Setting functions for the effect size calculation and table output
## Function for calculating the circular linear correlation
circular_cor <- function(x, y, rads = TRUE) {
  circlin.cor <- circlin.cor(x, y, rads = rads)
  R_squared <- circlin.cor[, 1]
  Pearsons_r <- sqrt(R_squared) 
  ## Applicable based on the characteristic of the simple linear regression
  return(data.frame(Pearsons_r = Pearsons_r, R_squared = R_squared))
}
```

```{r}
#| include: false
## Function for detecting and removing outliers
  # Detect inputs
remove_outliers <- function(sleepchar, scale_columns, memory = NULL) {

  # Detect rows to remove in the sleep data matrix
  rows_rem <- which(rowSums(abs(scale(sleepchar[, scale_columns])) > 3) > 0)
  print(paste(length(rows_rem), "rows removed:", paste(rows_rem, collapse = ", ")))
  sleepchar_rem <- if (length(rows_rem) > 0) sleepchar[-rows_rem, ] else sleepchar
  
  # Detect rows to remove in the memory data matrix
  if (!is.null(memory)) {
    memory_rem <- memory |> filter(!row_number() %in% rows_rem)
    print("Corrisponding rows removed in the memory matrix.")
    return(list(sleepchar_rem = sleepchar_rem, memory_rem = memory_rem))
  }
  return(sleepchar_rem)
}
```

```{r}
#| include: false
## Function for building tables for the data classification
cortable <- function(author, cptype, flip = TRUE, ...) {
  # Combine the grouped correlation matrices into a data frame
  cor_group <- data.frame(...)
  if (flip) cor_group <- t(cor_group)
  # Create the table caption
  cptype <- switch(cptype,"CP Phase", "SP Amplitude", "CP Strength", "CP Percentage")
  caption <- paste(author, cptype, "and Memory Pearson's r Correlation Table")
  
  # Generate the table for data extraction
  knitr::kable(cor_group, format = "markdown", caption = caption)
}
```

```{r}
#| include: false
## Store all functions to call during the data analysis
save(circular_cor, remove_outliers, cortable, file = "preprocessing_fun.RData")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Begin the scatterplot analysis for estimating effect sizes
## Import graphs to shinyDigitise
## Could be downloaded from the Github repository
## Donnelly2022 <- shinyDigitise("~/Desktop/SO-SP-Coupling/so-sp-coupling/Paper/Donnelly2022/Figure/")")
## Helfrich2018 <- shinyDigitise("~/Desktop/SO-SP-Coupling/so-sp-coupling/Paper/Helfrich2018/Figure/")
## Processed data saved in the same folder
```

## Schreiner2021

```{r}
#| warning: false
#| message: false
#| include: false
## Begin the calculation of effect sizes by preprocessed data
## Import source data from Schreiner 2021
Schreiner2021 <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Schreiner2021/Sourcedata/source-data-preprocessed.csv", show_col_types = FALSE)
## view(Schreiner2021)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation
sch_phase <- circular_cor(Schreiner2021$phase, Schreiner2021$retention)
knitr::kable(sch_phase,format ="markdown",caption ="Schreiner CP Phase and Memory Pearson's r Correlation Table",row.names = FALSE)
```

```{r}
#| include: false
## knitr::kable(result, format = "markdown")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate the coupling percentage and remove outlier(s)
Schreiner2021 <- Schreiner2021 |>
  mutate(
    spavg = (spobjects + spscenes)/2,
    cpavg = (cpobjects + cpscenes)/2,
    soavg = (soobjects + soscenes)/2,
    spsopct = cpavg/spavg,
    sosppct = cpavg/soavg)
Schreiner2021_rem <- remove_outliers(Schreiner2021, scale_columns = c("spsopct", "sosppct"))
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate summary statistics for the coupling percentage
favstats(~ spsopct, data = Schreiner2021_rem)
favstats(~ sosppct, data = Schreiner2021_rem)
## Test the normality condition for further interpretation
shapiro.test(Schreiner2021_rem$spsopct)
shapiro.test(Schreiner2021_rem$sosppct)
## Calculate the linear correlation between SO coupled SP and memory retention
cor1 <- cor(spsopct ~ retention, use = "complete", data = Schreiner2021_rem)
## Calculate the linear correlation between SP coupled SO and memory retention
cor2 <- cor(sosppct ~ retention, use = "complete", data = Schreiner2021_rem)
```


```{r}
#| warning: false
#| message: false
#| echo: false
cortable("Schreiner", 4, flip = FALSE, "SPcSO" = cor1, "SOcSP" = cor2)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Denis2021a

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Denis 2021a
Denis2021a <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Denis2021a/Sourcedata/sleepldf_so_ss_data.csv", show_col_types = FALSE)
## view(Denis2021a)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Filter out the stress group and remove outlier(s) for coupling strength
Denis2021a_str <- Denis2021a |>
  dplyr::select(cond, neu_hit_fa:neg_hit_fa, n3_cp_str_all)|>
  filter(cond == 2)|>
  mutate(avg_hit_fa = (neu_hit_fa*100 + emo_hit_fa*200)/300)
Denis2021a_str_rem <- remove_outliers(Denis2021a_str, scale_columns = "n3_cp_str_all")
## Calculate summary statistics for the coupling percentage
favstats(~ n3_cp_str_all, data = Denis2021a_str_rem)
## Test the normality condition for further interpretation
shapiro.test(Denis2021a_str_rem$n3_cp_str_all)
## Note: The distribution of coupling strength data deviates significantly (p < 0.02)
## from the normal distribution
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition
cor1 <- cor(neu_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cor2 <- cor(emo_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cor3 <- cor(pos_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cor4 <- cor(neg_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
## Calculate the weighted effect size for all conditions
cor5 <- cor(avg_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cortable("Denis", 3, flip = FALSE, "Neutral" = cor1, "Emotional" = cor2, "Positive" = cor3, "Negative" = cor4, "Weighted Average" = cor5)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Filter out the stress group and remove outlier(s) for coupling percentage
Denis2021a_per <- Denis2021a |>
  dplyr::select(cond, neu_hit_fa:neg_hit_fa, n3_cp_per_all)|>
  filter(cond == 2)|>
  mutate(avg_hit_fa = (neu_hit_fa*100 + emo_hit_fa*200)/300)
Denis2021a_per_rem <- remove_outliers(Denis2021a_per, scale_columns = "n3_cp_per_all")
## Calculate summary statistics for the coupling percentage
favstats(~ n3_cp_per_all, data = Denis2021a_per_rem)
## Test the normality condition for further interpretation
shapiro.test(Denis2021a_per_rem$n3_cp_per_all)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition
cor1 <- cor(neu_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
cor2 <-cor(emo_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
cor3 <-cor(pos_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
cor4 <-cor(neg_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
## Calculate the weighted effect size for all conditions
cor5 <-cor(avg_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per)
cortable("Denis", 4, flip = FALSE, "Neutral" = cor1, "Emotional" = cor2, "Positive" = cor3, "Negative" = cor4, "Weighted Average" = cor5)
```

```{r}
#| include: false
## Test robustness by the bootstrap method for nonnormality data
#> num_sim <- 10000
#> set.seed(1821)
#> bootstrap_result <- do(num_sim) * 
#>   cor(avg_hit_fa ~ n3_cp_str_all, data = resample(Denis2021a_str))
#> summary(bootstrap_result)

#> bootstrap_result <- as.numeric(bootstrap_result$cor)
#> ggplot(data.frame(x = bootstrap_result), aes(x = x)) +
#>   geom_histogram(binwidth = 0.05, color = "black", fill = "lightblue") +
#>   labs(title = "Histogram of Bootstrap Results",
#>        x = "Bootstrap Results (Pearson's r correlation)",
#>        y = "Frequency") +
#>   geom_vline(xintercept = mean(bootstrap_result), color = "black", linetype = "dashed") +
#>   geom_vline(xintercept = avg_cor, color = "black", linetype = "dashed")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Hahn2020

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Hahn 2020
Hahn_beh <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/behaviorals.csv", show_col_types = FALSE)
Hahn_chphase <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_phase.csv", show_col_types = FALSE)
Hahn_champ <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_amplitude.csv", show_col_types = FALSE)
Hahn_chstr <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_strength.csv", show_col_types = FALSE)
Hahn_adphase <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_phase.csv", show_col_types = FALSE)
Hahn_adamp <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_amplitude.csv", show_col_types = FALSE)
Hahn_adstr <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_strength.csv", show_col_types = FALSE)
Hahn_pct <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/percentage.csv", show_col_types = FALSE)
#> view(Hahn_beh)
#> view(Hahn_chphase)
#> view(Hahn_champ)
#> view(Hahn_chstr)
#> view(Hahn_adphase)
#> view(Hahn_adamp)
#> view(Hahn_adstr)
#> view(Hahn_pct)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Phase Preprocessing
## Calculate the mean preferred phase for each electrode location cluster
Hahn_chphase <- Hahn_chphase |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2)))
#> view(Hahn_chphase)
Hahn_adphase <- Hahn_adphase |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2)))
#> view(Hahn_adphase)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation for the child group
variables <- c("Favg", "Cavg", "POavg")
effect_sizech <- data.frame()
for (var in variables) {
  effect_varch <- circular_cor(Hahn_chphase[[var]], Hahn_beh$ch_diff)
  effect_sizech <- rbind(effect_sizech, effect_varch)
}
rownames(effect_sizech) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_sizech, format = "markdown", caption = "Hahn Child CP Phase and Memory Pearson's r Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation for the adolescent group
variables <- c("Favg", "Cavg", "POavg")
effect_sizead <- data.frame()
for (var in variables) {
  effect_varad <- circular_cor(Hahn_adphase[[var]], Hahn_beh$ad_diff)
  effect_sizead <- rbind(effect_sizead, effect_varad)
}
rownames(effect_sizead) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_sizead, format = "markdown", caption = "Hahn Adolescent CP Phase and Memory Pearson's r Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Spindle Amplitude Preprocessing
# Calculate the mean spindle amplitude for each electrode location cluster
Hahn_champ <- Hahn_champ |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_champ)
Hahn_adamp <- Hahn_adamp |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_adamp)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Detect and Remove outlier(s)
chresult <- remove_outliers(Hahn_champ, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_champ_rem <- chresult$sleepchar_rem
Hahn_chbeh_rem <- chresult$memory_rem
#> view(Hahn_champ_rem)
#> view(Hahn_chbeh_rem)
adresult <- remove_outliers(Hahn_adamp, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_adamp_rem <- adresult$sleepchar_rem
Hahn_adbeh_rem <- adresult$memory_rem
#> view(Hahn_adamp_rem)
#> view(Hahn_adbeh_rem)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each channel location
cor_ch <- c(
  Frontal = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_champ_rem$Favg, use = "complete"),
  Central = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_champ_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_champ_rem$POavg, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each channel location
cor_ad <- c(
  Frontal = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adamp_rem$Favg, use = "complete"),
  Central = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adamp_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adamp_rem$POavg, use = "complete")
)

# Create the table
cortable("Hahn", 2, flip = FALSE, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Strength Preprocessing
# Calculate the mean coupling strength for each electrode location cluster
Hahn_chstr <- Hahn_chstr |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_chstr)
Hahn_adstr <- Hahn_adstr |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_adstr)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Detect and Remove outlier(s)
chresult <- remove_outliers(Hahn_chstr, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_chstr_rem <- chresult$sleepchar_rem
Hahn_chbeh_rem <- chresult$memory_rem
#> view(Hahn_chstr_rem)
#> view(Hahn_chbeh_rem)
adresult <- remove_outliers(Hahn_adstr, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_adstr_rem <- adresult$sleepchar_rem
Hahn_adbeh_rem <- adresult$memory_rem
#> view(Hahn_adstr_rem)
#> view(Hahn_adbeh_rem)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each channel location
cor_ch <- c(
  Frontal = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$Favg, use = "complete"),
  Central = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$POavg, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each channel location
cor_ad <- c(
  Frontal = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$Favg, use = "complete"),
  Central = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$POavg, use = "complete")
)

# Create the table
cortable("Hahn", 3, flip = FALSE, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Percentage Preprocessing
## Detect and Remove outlier(s)
chpct <- remove_outliers(Hahn_pct, scale_columns = c("ch_n2", "ch_n3"), memory = Hahn_beh)
Hahn_chpct_rem <- chpct$sleepchar_rem
Hahn_chbeh_rem <- chpct$memory_rem

adpct <- remove_outliers(Hahn_pct, scale_columns = c("ad_n2", "ad_n3"), memory = Hahn_beh)
Hahn_adpct_rem <- adpct$sleepchar_rem
Hahn_adbeh_rem <- adpct$memory_rem
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each sleep stage
cor_ch <- c(
  N2 = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chpct_rem$ch_n2, use = "complete"),
  N3 = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chpct_rem$ch_n3, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each sleep stage
cor_ad <- c(
  N2 = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adpct_rem$ad_n2, use = "complete"),
  N3 = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adpct_rem$ad_n3, use = "complete")
)

# Create the table
cortable("Hahn", 4, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Kurz2023

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Kurz 2023
Kurz2023_raw <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Kurz2023/Sourcedata/dataDRMdevelopment.csv", show_col_types = FALSE)
#> view(Kurz2023_raw)
# Exclude participants from the wake group & with missing values
Kurz2023 <- Kurz2023_raw |>
  filter(Condition == "Sleep" & rowSums(is.na(cur_data()[, 46:84])) == 0) |>
  dplyr::select(7,46:84)
view(Kurz2023)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Coupling Phase Preprocessing
## Calculate the circular linear correlation
variables <- names(Kurz2023)[35:40]
effect_size <- data.frame()
for (var in variables) {
  effect_var <- circular_cor(Kurz2023[[var]], Kurz2023$DRM_correct)
  effect_size <- rbind(effect_size, effect_var)
}
rownames(effect_size) <- c("Slow Frontal", "Slow Central", "Slow Parietal","Fast Frontal", "Fast Central", "Fast Parietal")
knitr::kable(effect_size, format = "markdown", caption = "Kurz CP Phase and Memory Pearson's r Correlation Table")
## n = 30
```

```{r}
#| warning: false
#| message: false
#| include: false
## Spindle Amplitude Preprocessing
## Detect and Remove outlier(s)
Kurz2023amp <- remove_outliers(Kurz2023, scale_columns = c("SP_amplitude_NonREM_fast_frontal", "SP_amplitude_NonREM_fast_central", "SP_amplitude_NonREM_fast_parietal","SP_amplitude_NonREM_slow_frontal", "SP_amplitude_NonREM_slow_central", "SP_amplitude_NonREM_slow_parietal"))
#> view(Kurz2023amp)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(DRM_correct ~ SP_amplitude_NonREM_fast_frontal, use = "complete", data = Kurz2023amp),
  "Central" = cor(DRM_correct ~ SP_amplitude_NonREM_fast_central, use = "complete", data = Kurz2023amp),
  "Parietal" = cor(DRM_correct ~ SP_amplitude_NonREM_fast_parietal, use = "complete", data = Kurz2023amp))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(DRM_correct ~ SP_amplitude_NonREM_slow_frontal, use = "complete", data = Kurz2023amp),
  "Central " = cor(DRM_correct ~ SP_amplitude_NonREM_slow_central, use = "complete", data = Kurz2023amp),
  "Parietal" = cor(DRM_correct ~ SP_amplitude_NonREM_slow_parietal, use = "complete", data = Kurz2023amp))

# Create the table
cortable("Kurz", 2, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Strength Preprocessing
## Detect and Remove outlier(s)
Kurz2023str <- remove_outliers(Kurz2023, scale_columns = c("CouplStrengthOnlyCoupl_slow_frontal", "CouplStrengthOnlyCoupl_slow_central", "CouplStrengthOnlyCoupl_slow_parietal","CouplStrengthOnlyCoupl_fast_frontal", "CouplStrengthOnlyCoupl_fast_central", "CouplStrengthOnlyCoupl_fast_parietal"))
#> view(Kurz2023str)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast SP coupling and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_fast_frontal, use = "complete", data = Kurz2023str),
  "Central" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_fast_central, use = "complete", data = Kurz2023str),
  "Parietal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_fast_parietal, use = "complete", data = Kurz2023str))

# Calculate correlation coefficients between slow SP coupling and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_slow_frontal, use = "complete", data = Kurz2023str),
  "Central " = cor(DRM_correct ~ CouplStrengthOnlyCoupl_slow_central, use = "complete", data = Kurz2023str),
  "Parietal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_slow_parietal, use = "complete", data = Kurz2023str))

# Create the table
cortable("Kurz", 3, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Donnelly2022

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Donnelly 2022
eeg_download <- "https://github.com/Theaang/so-sp-coupling/raw/main/Paper/Donnelly2022/Sourcedata/sleep_study_eeg_summary_data_z.rds"
Donnelly_eeg <- readRDS(url(eeg_download, method="libcurl"))
beh_download <- "https://github.com/Theaang/so-sp-coupling/raw/main/Paper/Donnelly2022/Sourcedata/sleep_study_beh_psych_demographic_data.rds"
Donnelly_behrow <- readRDS(url(beh_download, method="libcurl"))
#> view(Donnelly_eeg)
#> view(Donnelly_behrow)

## Extract all datasets from the RDS file
Donnelly2022 <- list()
for (i in 1:nrow(Donnelly_eeg)) {
  Donnelly2022[[i]] <- Donnelly_eeg[[3]][[i]]
}
Donnellyamp_raw <- Donnelly2022[[14]]
Donnellystr_raw <- Donnelly2022[[20]]
Donnellyphase_raw <- Donnelly2022[[21]]
## N2sigpwr <- Donnelly2022[[1]]
## N3sigpwr <- Donnelly2022[[6]]
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Transform the memory data
# Calculate the memory retention rate
# Exclude participants from the patient group and missing values
Donnelly_beh <- Donnelly_behrow |>
  filter(group == "Sib") |>
  mutate(retention = accC_morning - accC_evening) |>
  filter(rowSums(is.na(cur_data()[, 26:27])) == 0)
#> view(Donnelly_beh)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Phase Preprocessing
# Filter unused groups and electrodes
Donnellyphase <- Donnellyphase_raw |>
  filter(group == "Sib" & !grepl("^FC|^T|^FP|^FT|^CP|^AF", electrode))

# Adjust the dataframe format for data extraction
Donnellyphase <- Donnellyphase |>
  pivot_wider(names_from = electrode,
              values_from = value,
              id_cols = subject)
#> view(Donnellyphase)

# Calculate the mean coupling phase for each electrode location cluster
Donnellyphase_avg <- Donnellyphase |>
  rowwise() |>
  mutate(
    Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, Fz)) * pi) / 180,
    Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz)) * pi) / 180,
    POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, Pz, PO3, PO4, O1, O2)) * pi) / 180)
Donnellyphase_avg <- Donnellyphase_avg[-7,]
#> view(Donnellyphase_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation
variables <- c("Favg", "Cavg", "POavg")
effect_size <- data.frame()
for (var in variables) {
  effect_var <- circular_cor(Donnellyphase_avg[[var]], Donnelly_beh$retention)
  effect_size <- rbind(effect_size, effect_var)
}
rownames(effect_size) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_size, format = "markdown", caption = "Donnelly CP Phase and Memory Pearson's r Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Spindle Amplitude Preprocessing
# Filter unused groups and electrodes
Donnellyamp <- Donnellyamp_raw |>
  filter(group == "Sib" & !grepl("^FC|^T|^FP|^FT|^CP|^AF", electrode))

# Adjust the dataframe format for data extraction
Donnellyamp <- Donnellyamp |>
  pivot_wider(names_from = electrode,
              values_from = value,
              id_cols = subject)
#> view(Donnellyamp)

# Calculate the mean spindle amplitude for each electrode location cluster
Donnellyamp_avg <- Donnellyamp |>
  rowwise() |>
  mutate(
    Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, Fz))),
    Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
    POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, Pz, PO3, PO4, O1, O2))))
Donnellyamp_avg <- Donnellyamp_avg[-7,]

# Detect and remove outlier(s)
Donnellyamp_avg <- remove_outliers(Donnellyamp_avg, scale_columns = c("Favg", "Cavg", "POavg"))

#> view(Donnellyamp_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between spindle amplitude and memory in each channel location
cor <- c(
  "Frontal" = cor(Donnelly_beh$retention ~ Donnellyamp_avg$Favg, use = "complete"),
  "Central" = cor(Donnelly_beh$retention ~ Donnellyamp_avg$Cavg, use = "complete"),
  "Parietal" = cor(Donnelly_beh$retention ~ Donnellyamp_avg$POavg, use = "complete"))

cortable("Donnelly", 2, "Correlation" = cor)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Strength Preprocessing
# Filter unused groups and electrodes
Donnellystr <- Donnellystr_raw |>
  filter(group == "Sib" & !grepl("^FC|^T|^FP|^FT|^CP|^AF", electrode))

# Adjust the dataframe format for data extraction
Donnellystr <- Donnellystr |>
  pivot_wider(names_from = electrode,
              values_from = value,
              id_cols = subject)
#> view(Donnellystr)

# Calculate the mean coupling strength for each electrode location cluster
Donnellystr_avg <- Donnellystr |>
  rowwise() |>
  mutate(
    Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, Fz))),
    Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
    POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, Pz, PO3, PO4, O1, O2))))
Donnellystr_avg <- Donnellystr_avg[-7,]

# Detect and remove outlier(s)
Donnellystr_avg <- remove_outliers(Donnellystr_avg, scale_columns = c("Favg", "Cavg", "POavg"))

#> view(Donnellystr_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between coupling strength and memory in each channel location
cor <- c(
  "Frontal" = cor(Donnelly_beh$retention ~ Donnellystr_avg$Favg, use = "complete"),
  "Central" = cor(Donnelly_beh$retention ~ Donnellystr_avg$Cavg, use = "complete"),
  "Parietal" = cor(Donnelly_beh$retention ~ Donnellystr_avg$POavg, use = "complete"))

cortable("Donnelly", 3, "Correlation" = cor)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Denis2022

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Denis 2022
Denis_files <- c("behaviour.csv", "fast_amplitude.csv", "slow_amplitude.csv", 
                "fast_power.csv", "slow_power.csv", "fast_consistency.csv", 
                "slow_consistency.csv", "fast_percent.csv", "slow_percent.csv", 
                "fast_phase.csv", "slow_phase.csv")
for (file in Denis_files) {
  file_url <- paste0("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Denis2022/Sourcedata/", file)
  data <- read.csv(file_url)
  data <- data[-c(18, 34), ] ## Remove empty rows
  assign(gsub(".csv", "", file), data)
}
behaviour_fast <- behaviour |>
  rowwise() |>
  mutate(
  change_pres = change_1pres)
## Create a separate behavior dataset for slow spindle data due to missing value
behaviour_slow = behaviour_fast[-c(5, 7, 12, 27, 28, 32), ]
## view(behaviour_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Phase Preprocessing
## Calculate the mean coupling phase for each electrode location cluster
fast_phase_avg <- fast_phase |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2))))
## view(fast_phase_avg)
slow_phase_avg <- slow_phase |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_phase_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
variables <- c("Favg", "Cavg", "POavg")
es_fast <- data.frame()
for (var in variables) {
ev_fast <- circular_cor(fast_phase_avg[[var]], behaviour_fast$change_pres)
es_fast <- rbind(es_fast, ev_fast)
}
es_slow <- data.frame()
for (var in variables) {
ev_slow <- circular_cor(slow_phase_avg[[var]], behaviour_slow$change_pres)
es_slow <- rbind(es_slow, ev_slow)
}
effect_size <- rbind(es_slow, es_fast)
rownames(effect_size) <- c("Slow Frontal", "Slow Central", "Slow Parietal","Fast Frontal", "Fast Central", "Fast Parietal")
knitr::kable(effect_size, format = "markdown", caption = "Denis CP Phase and Memory Pearson's r Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| include: false
fast_amplitude_avg <- fast_amplitude |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2))))
## view(fast_amplitude_avg)
slow_amplitude_avg <- slow_amplitude |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_amplitude_avg)
```


```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ fast_amplitude_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ fast_amplitude_avg$Cavg, use = "complete"),
  "Parietal" = cor(behaviour_fast$change_pres ~ fast_amplitude_avg$POavg, use = "complete"))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(behaviour_slow$change_pres ~ slow_amplitude_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_slow$change_pres ~ slow_amplitude_avg$Cavg, use = "complete"),
  "Parietal" = cor(behaviour_slow$change_pres ~ slow_amplitude_avg$POavg, use = "complete"))

# Create the table
cortable("Denis", 2, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
fast_consistency_avg <- fast_consistency |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2))))
## view(fast_consistency_avg)
slow_consistency_avg <- slow_consistency |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_consistency_avg)
```


```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ fast_consistency_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ fast_consistency_avg$Cavg, use = "complete"),
  "Parietal" = cor(behaviour_fast$change_pres ~ fast_consistency_avg$POavg, use = "complete"))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(behaviour_slow$change_pres ~ slow_consistency_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_slow$change_pres ~ slow_consistency_avg$Cavg, use = "complete"),
  "Parietal" = cor(behaviour_slow$change_pres ~ slow_consistency_avg$POavg, use = "complete"))

# Create the table
cortable("Denis", 3, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
fast_percent_avg <- fast_percent |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2))))
## view(fast_percent_avg)
slow_percent_avg <- slow_percent |>
rowwise() |>
mutate(
 Favg = (mean(c(F1, F2, F3, F4, F5, F6, F7, F8, Fz))),
 Cavg = (mean(c(C1, C2, C3, C4, C5, C6, Cz))),
 POavg = (mean(c(P1, P2, P3, P4, P5, P6, P7, P8, Pz, PO3, PO4, PO7, PO8, POz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_percent_avg)
```


```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ fast_percent_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ fast_percent_avg$Cavg, use = "complete"),
  "Parietal" = cor(behaviour_fast$change_pres ~ fast_percent_avg$POavg, use = "complete"))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ slow_percent_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ slow_percent_avg$Cavg, use = "complete"),
  "Parietal" = cor(behaviour_fast$change_pres ~ slow_percent_avg$POavg, use = "complete"))

# Create the table
cortable("Denis", 4, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```