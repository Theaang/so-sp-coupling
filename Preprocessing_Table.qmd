---
title: "Effect Size Preprocessing Tables"
format: pdf
editor: visual
author: "2023-08-02"
date-format: iso
toc: true
geometry:
      - top=25.4mm
      - left=25.4mm
      - right=25.4mm
      - bottom=25.4mm
---

```{r}
#| warning: false
#| message: false
#| label: setup
#| echo: false
## Load required packages
library(mosaic)
library(tidyverse)
library(knitr)
library(kableExtra)
library(tidyr)
library(Stat2Data)
library(dplyr)
library(meta)
library(metafor)
library(dmetar)
library(metaDigitise)
library(ICC)
library(wildmeta)
library(future)
library(shinyDigitise)
library(CircStats)
library(Directional)
options(digits = 4)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "",
                      tidy=FALSE, size="small")
```

```{r}
#| warning: false
#| message: false
## All codes presented here is copied from the "Preprocessing.qmd" file to
## extract all the tables and eliminate any code snippets and comments
```

```{r}
#| echo: false
## Setting functions for the effect size calculation
## Function for calculating the circular linear correlation
circular_cor <- function(x, y, rads = TRUE) {
  circlin.cor <- circlin.cor(x, y, rads = rads)
  R_squared <- circlin.cor[, 1]
  Pearsons_r <- sqrt(R_squared)
  return(data.frame(Pearsons_r = Pearsons_r, R_squared = R_squared))
}
```

```{r}
#| echo: false
## Function for detecting and removing outliers
  # Detect inputs
remove_outliers <- function(sleepchar, scale_columns, memory = NULL) {
  if (!is.null(memory) && length(scale_columns) > 0 && !all(scale_columns %in% colnames(sleepchar))) {
    scale_columns <- which(names(sleepchar) %in% scale_columns)
  }

  # Detect rows to remove
  rows_rem <- which(rowSums(abs(scale(sleepchar[, scale_columns])) > 3) > 0)
  print(paste("Number of rows removed:", length(rows_rem)))

  if (length(rows_rem) > 0) {
    sleepchar_rem <- sleepchar[-rows_rem, ]
  } else {
    sleepchar_rem <- sleepchar
  }
  
  if (!is.null(memory)) {
    if (length(rows_rem) > 0) {
      memory_rem <- memory[-rows_rem, ]
      print("Rows removed in memory.")
    } else {
      memory_rem <- memory
      print("No rows to remove in memory.")
    }
    return(list(sleepchar_rem = sleepchar_rem, memory_rem = memory_rem))
  }

  return(sleepchar_rem)
}
```

```{r}
#| echo: false
## Function for building tables for the data classification
cortable <- function(author, cptype, flip = TRUE, ...) {
  # Combine the correlation matrices into a data frame and transpose it
  cor_group <- data.frame(...)
  
  if (flip) cor_group <- t(cor_group)
  # Create the table caption
  cptype <- switch(cptype,"CP Phase", "SP Peak Amplitude", "CP Strength", "CP Percentage")
  caption <- paste(author, cptype, "and Memory Pearson's r Correlation Table")
  
  # Generate the table calling knitr::kable
  knitr::kable(cor_group, format = "markdown", caption = caption)
}
```

```{r}
#| echo: false
save(circular_cor, remove_outliers, cortable, file = "preprocessing_fun.RData")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Begin the scatterplot analysis for estimating effect sizes
## Import graphs to shinyDigitise
## Could be downloaded from the Github repository
## Donnelly2022 <- shinyDigitise("~/Desktop/SO-SP-Coupling/so-sp-coupling/Paper/Donnelly2022/Figure/")")
## Helfrich2018 <- shinyDigitise("~/Desktop/SO-SP-Coupling/so-sp-coupling/Paper/Helfrich2018/Figure/")
## Processed data saved in the same folder
```

## Schreiner2021

```{r}
#| warning: false
#| message: false
#| echo: false
## Begin the calculation of effect sizes by preprocessed data
## Import source data from Schreiner 2021
Schreiner2021 <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Schreiner2021/Sourcedata/source-data-preprocessed.csv", show_col_types = FALSE)
## view(Schreiner2021)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation
sch_phase <- circular_cor(Schreiner2021$phase, Schreiner2021$retention)
knitr::kable(sch_phase,format ="markdown",caption ="Schreiner CP Phase and Memory Pearson's r Correlation Table",row.names = FALSE)
```

```{r}
#| echo: false
## knitr::kable(result, format = "markdown")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate the coupling percentage and remove outlier(s)
Schreiner2021 <- Schreiner2021 |>
  mutate(
    spavg = (spobjects + spscenes)/2,
    cpavg = (cpobjects + cpscenes)/2,
    soavg = (soobjects + soscenes)/2,
    spsopct = cpavg/spavg,
    sosppct = cpavg/soavg)
Schreiner2021_rem <- remove_outliers(Schreiner2021, scale_columns = c("spsopct", "sosppct"))
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate summary statistics for the coupling percentage
favstats(~ spsopct, data = Schreiner2021_rem)
favstats(~ sosppct, data = Schreiner2021_rem)
## Test the normality condition for further interpretation
shapiro.test(Schreiner2021_rem$spsopct)
shapiro.test(Schreiner2021_rem$sosppct)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the linear correlation between SO coupled SP and memory retention
cor1 <- cor(spsopct ~ retention, use = "complete", data = Schreiner2021_rem)
## Calculate the linear correlation between SP coupled SO and memory retention
cor2 <- cor(sosppct ~ retention, use = "complete", data = Schreiner2021_rem)
cortable("Schreiner", 4, flip = FALSE, "SPcSO" = cor1, "SOcSP" = cor2)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Denis2021a

```{r}
#| warning: false
#| message: false
#| echo: false
## Import source data from Denis 2021a
Denis2021a <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Denis2021a/Sourcedata/sleepldf_so_ss_data.csv", show_col_types = FALSE)
## view(Denis2021a)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Filter out the stress group and remove outlier(s) for coupling strength
Denis2021a_str <- Denis2021a |>
  dplyr::select(cond, neu_hit_fa:neg_hit_fa, n3_cp_str_all)|>
  filter(cond == 2)|>
  mutate(avg_hit_fa = (neu_hit_fa*100 + emo_hit_fa*200)/300)
Denis2021a_str_rem <- remove_outliers(Denis2021a_str, scale_columns = "n3_cp_str_all")
## Calculate summary statistics for the coupling percentage
favstats(~ n3_cp_str_all, data = Denis2021a_str_rem)
## Test the normality condition for further interpretation
shapiro.test(Denis2021a_str_rem$n3_cp_str_all)
## Note: The distribution of coupling strength data deviates significantly (p < 0.02)
## from the normal distribution
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition
cor1 <- cor(neu_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cor2 <- cor(emo_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cor3 <- cor(pos_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cor4 <- cor(neg_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
## Calculate the weighted effect size for all conditions
cor5 <- cor(avg_hit_fa ~ n3_cp_str_all, use = "complete", data = Denis2021a_str_rem)
cortable("Denis", 3, flip = FALSE, "Neutral" = cor1, "Emotional" = cor2, "Positive" = cor3, "Negative" = cor4, "Weighted Average" = cor5)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Filter out the stress group and remove outlier(s) for coupling percentage
Denis2021a_per <- Denis2021a |>
  dplyr::select(cond, neu_hit_fa:neg_hit_fa, n3_cp_per_all)|>
  filter(cond == 2)|>
  mutate(avg_hit_fa = (neu_hit_fa*100 + emo_hit_fa*200)/300)
Denis2021a_per_rem <- remove_outliers(Denis2021a_per, scale_columns = "n3_cp_per_all")
## Calculate summary statistics for the coupling percentage
favstats(~ n3_cp_per_all, data = Denis2021a_per_rem)
## Test the normality condition for further interpretation
shapiro.test(Denis2021a_per_rem$n3_cp_per_all)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition
cor1 <- cor(neu_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
cor2 <-cor(emo_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
cor3 <-cor(pos_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
cor4 <-cor(neg_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per_rem)
## Calculate the weighted effect size for all conditions
cor5 <-cor(avg_hit_fa ~ n3_cp_per_all, use = "complete", data = Denis2021a_per)
cortable("Denis", 4, flip = FALSE, "Neutral" = cor1, "Emotional" = cor2, "Positive" = cor3, "Negative" = cor4, "Weighted Average" = cor5)
```

```{r}
#| echo: false
## Test robustness by the bootstrap method for nonnormality data
#> num_sim <- 10000
#> set.seed(1821)
#> bootstrap_result <- do(num_sim) * 
#>   cor(avg_hit_fa ~ n3_cp_str_all, data = resample(Denis2021a_str))
#> summary(bootstrap_result)

#> bootstrap_result <- as.numeric(bootstrap_result$cor)
#> ggplot(data.frame(x = bootstrap_result), aes(x = x)) +
#>   geom_histogram(binwidth = 0.05, color = "black", fill = "lightblue") +
#>   labs(title = "Histogram of Bootstrap Results",
#>        x = "Bootstrap Results (Pearson's r correlation)",
#>        y = "Frequency") +
#>   geom_vline(xintercept = mean(bootstrap_result), color = "black", linetype = "dashed") +
#>   geom_vline(xintercept = avg_cor, color = "black", linetype = "dashed")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Hahn2020

```{r}
#| warning: false
#| message: false
#| echo: false
## Import source data from Hahn 2020
Hahn_beh <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/behaviorals.csv", show_col_types = FALSE)
Hahn_chphase <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_phase.csv", show_col_types = FALSE)
Hahn_champ <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_amplitude.csv", show_col_types = FALSE)
Hahn_chstr <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_strength.csv", show_col_types = FALSE)
Hahn_adphase <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_phase.csv", show_col_types = FALSE)
Hahn_adamp <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_amplitude.csv", show_col_types = FALSE)
Hahn_adstr <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_strength.csv", show_col_types = FALSE)
Hahn_pct <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/percentage.csv", show_col_types = FALSE)
#> view(Hahn_beh)
#> view(Hahn_chphase)
#> view(Hahn_champ)
#> view(Hahn_chstr)
#> view(Hahn_adphase)
#> view(Hahn_adamp)
#> view(Hahn_adstr)
#> view(Hahn_pct)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Coupling Phase Preprocessing
## Calculate the mean preferred phase in each specified channel location (F,C,P&O) for both groups
Hahn_chphase <- Hahn_chphase |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2)))
#> view(Hahn_chphase)
Hahn_adphase <- Hahn_adphase |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2)))
#> view(Hahn_adphase)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation for the child group
variables <- c("Favg", "Cavg", "POavg")
effect_sizech <- data.frame()
for (var in variables) {
  effect_varch <- circular_cor(Hahn_chphase[[var]], Hahn_beh$ch_diff)
  effect_sizech <- rbind(effect_sizech, effect_varch)
}
rownames(effect_sizech) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_sizech, format = "markdown", caption = "Hahn Child CP Phase and Memory Pearson's r Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation for the adolescent group
variables <- c("Favg", "Cavg", "POavg")
effect_sizead <- data.frame()
for (var in variables) {
  effect_varad <- circular_cor(Hahn_adphase[[var]], Hahn_beh$ad_diff)
  effect_sizead <- rbind(effect_sizead, effect_varad)
}
rownames(effect_sizead) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_sizead, format = "markdown", caption = "Hahn Adolescent CP Phase and Memory Pearson's r Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Coupling Strength Preprocessing
## Calculate the mean strength in each specified channel location (F,C,P&O) for both groups
Hahn_chstr <- Hahn_chstr |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_chstr)
Hahn_adstr <- Hahn_adstr |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_adstr)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Detect and Remove outlier(s)
chresult <- remove_outliers(Hahn_chstr, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_chstr_rem <- chresult$sleepchar_rem
Hahn_chbeh_rem <- chresult$memory_rem
#> view(Hahn_chstr_rem)
#> view(Hahn_chbeh_rem)
adresult <- remove_outliers(Hahn_adstr, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_adstr_rem <- adresult$sleepchar_rem
Hahn_adbeh_rem <- adresult$memory_rem
#> view(Hahn_adstr_rem)
#> view(Hahn_adbeh_rem)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each channel location
cor_ch <- c(
  Frontal = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$Favg, use = "complete"),
  Central = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$POavg, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each channel location
cor_ad <- c(
  Frontal = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$Favg, use = "complete"),
  Central = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$POavg, use = "complete")
)

# Create the table
cortable("Hahn", 3, flip = FALSE, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Percentage Preprocessing
## Detect and Remove outlier(s)
chpct <- remove_outliers(Hahn_pct, scale_columns = c("ch_n2", "ch_n3"), memory = Hahn_beh)
Hahn_chpct_rem <- chpct$sleepchar_rem
Hahn_chbeh_rem <- chpct$memory_rem

adpct <- remove_outliers(Hahn_pct, scale_columns = c("ad_n2", "ad_n3"), memory = Hahn_beh)
Hahn_adpct_rem <- adpct$sleepchar_rem
Hahn_adbeh_rem <- adpct$memory_rem
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each sleep stage
cor_ch <- c(
  N2 = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chpct_rem$ch_n2, use = "complete"),
  N3 = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chpct_rem$ch_n3, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each sleep stage
cor_ad <- c(
  N2 = cor(Hahn_chbeh_rem$ad_diff ~ Hahn_adpct_rem$ad_n2, use = "complete"),
  N3 = cor(Hahn_chbeh_rem$ad_diff ~ Hahn_adpct_rem$ad_n3, use = "complete")
)

# Create the table
cortable("Hahn", 4, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```
