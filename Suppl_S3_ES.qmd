---
title: "Supplemental Material 3: Preprocessed Effect Sizes from Invididual Source Data"
format: pdf
editor: visual
author: "Author"
date: "2023-08-10"
date-format: iso
toc: true
toc-title: Table of Contents
---

```{r}
#| warning: false
#| message: false
#| include: false
#| label: setup
## Load required packages
library(mosaic)
library(tidyverse)
library(knitr)
library(kableExtra)
library(tidyr)
library(Stat2Data)
library(dplyr)
library(meta)
library(metafor)
library(dmetar)
library(metaDigitise)
library(ICC)
library(wildmeta)
library(future)
library(shinyDigitise)
library(CircStats)
library(Directional)
options(digits = 4)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "",
                      tidy=FALSE, size="small")
```

# I. Statement

All studies that provided processed individual sleep and memory measurement data by authors have undergone preprocessing or reanalysis to estimate correlation coefficients using standardized measurement methods selected for the meta-analysis. We are unable to disclose the source data due to copyright restrictions associated with the original studies. Instead, we will directly report the preprocessed effect sizes and formulas used. Individuals or groups who are interested in any source dataset should contact the authors of the original studies directly.

\newpage

In cases where meta-analysis authors reached out to the original study authors via email to obtain effect sizes, if the original study authors chose to provide processed individual datasets rather than reporting effect sizes directly, neither party requested or exchanged any information that could potentially expose the personal identities of individual participants. The data may have been sorted, merged or excluded based on the methods outlined in the original studies and the moderator selection in the meta-analysis. All data processing was performed within the Quarto document of R Studio version 2023.6.1.524 (Posit Team, 2023) using the R language (R Core Team, 2022) Not all effect sizes reported in this material will necessarily be used in the meta-analysis, contingent upon the inclusion criteria and moderators.

# II. Formulas

## Pearson Product-Moment Correlation Coefficient

$$ r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}
    {\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2 \sum_{i=1}^{n}(y_i - \bar{y})^2}} \tag{1} \label{eq:corr} $$

## Circular-Linear Correlation Coefficient

$$R = \sqrt{\frac{r_{12}^2 + r_{13}^2 + 2 \cdot r_{12} \cdot r_{13} \cdot r_{23}}{1 - r_{23}^2}}\tag{2}$$

where $$r_{12} = \text{corr}(x, \cos \theta), \,r_{13} = \text{corr}(x, \sin \theta), \,\text{and} \, r_{23} = \text{corr}(\cos \theta, \sin \theta) \quad$$ $corr$ function refers to the Pearson's r formula in \eqref{eq:corr} (Mardia, 1976)

# III. Effect Sizes

```{r}
#| include: false
## Setting functions for the effect size calculation and table output
## Function for calculating the circular linear correlation
circular_cor <- function(x, y, rads = TRUE) {
  circlin.cor <- circlin.cor(x, y, rads = rads)
  R.squared <- circlin.cor[, 1]
  Circlin.R <- sqrt(R.squared)
  ## Applicable based on the characteristic of the simple linear regression
  return(data.frame(Circlin.R = Circlin.R, R.squared = R.squared))
}
```

```{r}
#| include: false
## Function for detecting and removing outliers
  # Detect inputs
remove_outliers <- function(sleepchar, scale_columns, memory = NULL) {

  # Detect rows to remove in the sleep data matrix
  rows_rem <- which(rowSums(abs(scale(sleepchar[, scale_columns])) > 3) > 0)
  print(paste(length(rows_rem), "rows removed:", paste(rows_rem, collapse = ", ")))
  sleepchar_rem <- if (length(rows_rem) > 0) sleepchar[-rows_rem, ] else sleepchar
  
  # Detect rows to remove in the memory data matrix
  if (!is.null(memory)) {
    memory_rem <- memory |> filter(!row_number() %in% rows_rem)
    print("Corrisponding rows removed in the memory matrix.")
    return(list(sleepchar_rem = sleepchar_rem, memory_rem = memory_rem))
  }
  return(sleepchar_rem)
}
```

```{r}
#| include: false
## Function for building tables for the data classification
cortable <- function(author, cptype, flip = TRUE, ...) {
  # Combine the grouped correlation matrices into a data frame
  cor_group <- data.frame(...)
  if (flip) cor_group <- t(cor_group)
  # Create the table caption
  cptype <- switch(cptype,"CP Phase", "SP Amplitude", "CP Strength", "CP Percentage")
  caption <- paste(author, cptype, "and Memory Pearson's r Correlation Table")
  
  # Generate the table for data extraction
  knitr::kable(cor_group, format = "markdown", caption = caption)
}
```

```{r}
#| include: false
## Store all functions to call during the data analysis
save(circular_cor, remove_outliers, cortable, file = "preprocessing_fun.RData")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Begin the scatterplot analysis for estimating effect sizes
## Import graphs to shinyDigitise
## Could be downloaded from the Github repository
## Donnelly2022 <- shinyDigitise("~/Desktop/SO-SP-Coupling/so-sp-coupling/Paper/Donnelly2022/Figure/")")
## Helfrich2018 <- shinyDigitise("~/Desktop/SO-SP-Coupling/so-sp-coupling/Paper/Helfrich2018/Figure/")
## Processed data saved in the same folder
```

## Schreiner2021

```{r}
#| warning: false
#| message: false
#| include: false
## Begin the calculation of effect sizes by preprocessed data
## Import source data from Schreiner 2021
Schreiner2021 <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Schreiner2021/Sourcedata/source-data-preprocessed.csv", show_col_types = FALSE)
Schreiner2021addtl <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Schreiner2021/Sourcedata/additional.csv", show_col_types = FALSE)
## view(Schreiner2021)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation
sch_phase <- circular_cor(Schreiner2021$phase, Schreiner2021$retention)
## knitr::kable(sch_phase,format ="markdown",caption ="Schreiner CP Phase and Memory Circlin R Correlation Table",row.names = FALSE)
```

```{r}
#| include: false
## knitr::kable(result, format = "markdown")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate the coupling percentage and remove outlier(s)
Schreiner2021 <- Schreiner2021 |>
  mutate(
    spavg = (spobjects + spscenes)/2,
    cpavg = (cpobjects + cpscenes)/2,
    soavg = (soobjects + soscenes)/2,
    spsopct = cpavg/spavg,
    sosppct = cpavg/soavg)
Schreiner2021addtl <- Schreiner2021addtl |>
  mutate(
    spamp = (object_amp + scene_amp)/2,
    cpstr = (object_str + scene_str)/2)
Schreiner2021_rem <- remove_outliers(Schreiner2021, scale_columns = c("spsopct", "sosppct"))
Schreiner2021addtl_rem <- remove_outliers(Schreiner2021addtl, scale_columns = c("spamp", "cpstr"))
```

```{r}
#| warning: false
#| message: false
#| echo: false
cor1 <- cor(Schreiner2021addtl_rem$spamp ~ Schreiner2021_rem$retention, use = "complete")
## cortable("Schreiner", 2, flip = FALSE, "Correlation" = cor1)
cor2 <- cor(Schreiner2021addtl_rem$cpstr ~ Schreiner2021_rem$retention, use = "complete")
## cortable("Schreiner", 3, flip = FALSE, "Correlation" = cor2)

```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate summary statistics for the coupling percentage
favstats(~ spsopct, data = Schreiner2021_rem)
favstats(~ sosppct, data = Schreiner2021_rem)
## Test the normality condition for further interpretation
shapiro.test(Schreiner2021_rem$spsopct)
shapiro.test(Schreiner2021_rem$sosppct)
## Calculate the linear correlation between SO coupled SP and memory retention
cor3 <- cor(spsopct ~ retention, use = "complete", data = Schreiner2021_rem)
## Calculate the linear correlation between SP coupled SO and memory retention
cor4 <- cor(sosppct ~ retention, use = "complete", data = Schreiner2021_rem)
## cortable("Schreiner", 4, flip = FALSE, "SPcSO" = cor3, "SOcSP" = cor4)
```

```{r}
#| warning: false
#| message: false
#| echo: false
effect_size <- rbind(sch_phase, cor1, cor2, cor3, cor4)
knitr::kable(data.frame("Phase" = sch_phase, "Amplitude" = cor1, "Strength" = cor2, "SPcSO" = cor3, "SOcSP" = cor4), format = "markdown", caption = "Schreiner 2021 Coupling and Memory Correlation Table", row.names = FALSE)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Denis2021a

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Denis 2021a
Denis2021a <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Denis2021a/Sourcedata/ejn_data.csv", show_col_types = FALSE)
#> view(Denis2021a)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Filter out the stress group and weight the memory score
Denis2021a <- Denis2021a |>
  filter(cond == "control")|>
  mutate(avg_hit_fa = (neu_hit_fa*100 + emo_hit_fa*200)/300)
## Detect and remove outlier(s)
Denis2021a_amp_rem <- remove_outliers(Denis2021a, scale_columns = c("n2_fast_amplitude", "n3_fast_amplitude"))
Denis2021a_str_rem<- remove_outliers(Denis2021a, scale_columns = c("n2_fast_consistency","n3_fast_consistency"))
Denis2021a_per_rem<- remove_outliers(Denis2021a, scale_columns = c("n2_fast_ss_coupled_percent", "n3_fast_ss_coupled_percent"))
## Calculate summary statistics for the coupling percentage
## favstats(~ n3_cp_str_all, data = Denis2021a_str_rem)
## Test the normality condition for further interpretation
## shapiro.test(Denis2021a_str_rem$n3_cp_str_all)
## Note: The distribution of coupling strength data deviates significantly (p < 0.02)
## from the normal distribution
```

```{r}
#| warning: false
#| message: false
#| echo: false
variables <- c("neu_hit_fa", "emo_hit_fa", "avg_hit_fa")
es_n2 <- data.frame()
for (var in variables) {
ev_n2 <- circular_cor(Denis2021a$n2_fast_phase, Denis2021a[[var]])
es_n2 <- rbind(es_n2, ev_n2)
}
es_n3 <- data.frame()
for (var in variables) {
ev_n3 <- circular_cor(Denis2021a$n3_fast_phase, Denis2021a[[var]])
es_n3 <- rbind(es_n3, ev_n3)
}
effect_size <- rbind(es_n2, es_n3)
rownames(effect_size) <- c("N2 Neutral", "N2 Emotional", "N2 Weighted","N3 Neutral", "N3 Emotional", "N3 Weighted")
knitr::kable(effect_size, format = "markdown", caption = "Denis 2021 CP Phase and Memory Circular Linear Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition and pooled result
cor_n2 <- c(
  Neutral = cor(neu_hit_fa ~ n2_fast_amplitude, use = "complete", data = Denis2021a_amp_rem),
  Emotional = cor(emo_hit_fa ~ n2_fast_amplitude, use = "complete", data = Denis2021a_amp_rem),
  Weighted = cor(avg_hit_fa ~ n2_fast_amplitude, use = "complete", data = Denis2021a_amp_rem)
)
cor_n3 <- c(
  Neutral = cor(neu_hit_fa ~ n3_fast_amplitude, use = "complete", data = Denis2021a_amp_rem),
  Emotional = cor(emo_hit_fa ~ n3_fast_amplitude, use = "complete", data = Denis2021a_amp_rem),
  Weighted = cor(avg_hit_fa ~ n3_fast_amplitude, use = "complete", data = Denis2021a_amp_rem)
)
cortable("Denis 2021", 2, flip = FALSE, "nREM2" = cor_n2, "nREM3" = cor_n3)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition and pooled result
cor_n2 <- c(
  Neutral = cor(neu_hit_fa ~ n2_fast_consistency, use = "complete", data = Denis2021a_str_rem),
  Emotional = cor(emo_hit_fa ~ n2_fast_consistency, use = "complete", data = Denis2021a_str_rem),
  Weighted = cor(avg_hit_fa ~ n2_fast_consistency, use = "complete", data = Denis2021a_str_rem)
)
cor_n3 <- c(
  Neutral = cor(neu_hit_fa ~ n3_fast_consistency, use = "complete", data = Denis2021a_str_rem),
  Emotional = cor(emo_hit_fa ~ n3_fast_consistency, use = "complete", data = Denis2021a_str_rem),
  Weighted = cor(avg_hit_fa ~ n3_fast_consistency, use = "complete", data = Denis2021a_str_rem)
)
cortable("Denis 2021", 3, flip = FALSE, "nREM2" = cor_n2, "nREM3" = cor_n3)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the effect size for each emotional condition and pooled result
cor_n2 <- c(
  Neutral = cor(neu_hit_fa ~ n2_fast_ss_coupled_percent, use = "complete", data = Denis2021a_per_rem),
  Emotional = cor(emo_hit_fa ~ n2_fast_ss_coupled_percent, use = "complete", data = Denis2021a_per_rem),
  Weighted = cor(avg_hit_fa ~ n2_fast_ss_coupled_percent, use = "complete", data = Denis2021a_per_rem)
)
cor_n3 <- c(
  Neutral = cor(neu_hit_fa ~ n3_fast_ss_coupled_percent, use = "complete", data = Denis2021a_per_rem),
  Emotional = cor(emo_hit_fa ~ n3_fast_ss_coupled_percent, use = "complete", data = Denis2021a_per_rem),
  Weighted = cor(avg_hit_fa ~ n3_fast_ss_coupled_percent, use = "complete", data = Denis2021a_per_rem)
)
cortable("Denis 2021", 4, flip = FALSE, "nREM2" = cor_n2, "nREM3" = cor_n3)
```

```{r}
#| include: false
## Test robustness by the bootstrap method for nonnormality data
#> num_sim <- 10000
#> set.seed(1821)
#> bootstrap_result <- do(num_sim) * 
#>   cor(avg_hit_fa ~ n3_cp_str_all, data = resample(Denis2021a_str))
#> summary(bootstrap_result)

#> bootstrap_result <- as.numeric(bootstrap_result$cor)
#> ggplot(data.frame(x = bootstrap_result), aes(x = x)) +
#>   geom_histogram(binwidth = 0.05, color = "black", fill = "lightblue") +
#>   labs(title = "Histogram of Bootstrap Results",
#>        x = "Bootstrap Results (Pearson's r correlation)",
#>        y = "Frequency") +
#>   geom_vline(xintercept = mean(bootstrap_result), color = "black", linetype = "dashed") +
#>   geom_vline(xintercept = avg_cor, color = "black", linetype = "dashed")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

\newpage

## Hahn2020

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Hahn 2020
Hahn_beh <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/behaviorals.csv", show_col_types = FALSE)
Hahn_chphase <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_phase.csv", show_col_types = FALSE)
Hahn_champ <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_amplitude.csv", show_col_types = FALSE)
Hahn_chstr <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/child_strength.csv", show_col_types = FALSE)
Hahn_adphase <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_phase.csv", show_col_types = FALSE)
Hahn_adamp <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_amplitude.csv", show_col_types = FALSE)
Hahn_adstr <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/adolescent_strength.csv", show_col_types = FALSE)
Hahn_pct <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2020/Source%20Data/percentage.csv", show_col_types = FALSE)
#> view(Hahn_beh)
#> view(Hahn_chphase)
#> view(Hahn_champ)
#> view(Hahn_chstr)
#> view(Hahn_adphase)
#> view(Hahn_adamp)
#> view(Hahn_adstr)
#> view(Hahn_pct)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Phase Preprocessing
## Calculate the mean preferred phase for each electrode location cluster
Hahn_chphase <- Hahn_chphase |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2)))
#> view(Hahn_chphase)
Hahn_adphase <- Hahn_adphase |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2)))
#> view(Hahn_adphase)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation for the child group
variables <- c("Favg", "Cavg", "POavg")
effect_sizech <- data.frame()
for (var in variables) {
  effect_varch <- circular_cor(Hahn_chphase[[var]], Hahn_beh$ch_diff)
  effect_sizech <- rbind(effect_sizech, effect_varch)
}
rownames(effect_sizech) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_sizech, format = "markdown", caption = "Hahn 2020 Child CP Phase and Memory Circular Linear Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation for the adolescent group
variables <- c("Favg", "Cavg", "POavg")
effect_sizead <- data.frame()
for (var in variables) {
  effect_varad <- circular_cor(Hahn_adphase[[var]], Hahn_beh$ad_diff)
  effect_sizead <- rbind(effect_sizead, effect_varad)
}
rownames(effect_sizead) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_sizead, format = "markdown", caption = "Hahn 2020 Adolescent CP Phase and Memory Circular Linear Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Spindle Amplitude Preprocessing
# Calculate the mean spindle amplitude for each electrode location cluster
Hahn_champ <- Hahn_champ |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_champ)
Hahn_adamp <- Hahn_adamp |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_adamp)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Detect and Remove outlier(s)
chresult <- remove_outliers(Hahn_champ, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_champ_rem <- chresult$sleepchar_rem
Hahn_chbeh_rem <- chresult$memory_rem
#> view(Hahn_champ_rem)
#> view(Hahn_chbeh_rem)
adresult <- remove_outliers(Hahn_adamp, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_adamp_rem <- adresult$sleepchar_rem
Hahn_adbeh_rem <- adresult$memory_rem
#> view(Hahn_adamp_rem)
#> view(Hahn_adbeh_rem)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each channel location
cor_ch <- c(
  Frontal = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_champ_rem$Favg, use = "complete"),
  Central = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_champ_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_champ_rem$POavg, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each channel location
cor_ad <- c(
  Frontal = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adamp_rem$Favg, use = "complete"),
  Central = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adamp_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adamp_rem$POavg, use = "complete")
)

# Create the table
cortable("Hahn 2020", 2, flip = FALSE, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Strength Preprocessing
# Calculate the mean coupling strength for each electrode location cluster
Hahn_chstr <- Hahn_chstr |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_chstr)
Hahn_adstr <- Hahn_adstr |>
  rowwise() |>
  mutate(
    Favg = mean(c(F3, Fz, F4)),
    Cavg = mean(c(C3, Cz, C4)),
    POavg = mean(c(P3, Pz, P4, O1, O2))) |>
  dplyr::select(Favg, Cavg, POavg)
#> view(Hahn_adstr)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Detect and Remove outlier(s)
chresult <- remove_outliers(Hahn_chstr, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_chstr_rem <- chresult$sleepchar_rem
Hahn_chbeh_rem <- chresult$memory_rem
#> view(Hahn_chstr_rem)
#> view(Hahn_chbeh_rem)
adresult <- remove_outliers(Hahn_adstr, scale_columns = c("Favg", "Cavg", "POavg"), memory = Hahn_beh)
Hahn_adstr_rem <- adresult$sleepchar_rem
Hahn_adbeh_rem <- adresult$memory_rem
#> view(Hahn_adstr_rem)
#> view(Hahn_adbeh_rem)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each channel location
cor_ch <- c(
  Frontal = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$Favg, use = "complete"),
  Central = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chstr_rem$POavg, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each channel location
cor_ad <- c(
  Frontal = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$Favg, use = "complete"),
  Central = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adstr_rem$POavg, use = "complete")
)

# Create the table
cortable("Hahn 2020", 3, flip = FALSE, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Percentage Preprocessing
## Detect and Remove outlier(s)
chpct <- remove_outliers(Hahn_pct, scale_columns = c("ch_n2", "ch_n3"), memory = Hahn_beh)
Hahn_chpct_rem <- chpct$sleepchar_rem
Hahn_chbeh_rem <- chpct$memory_rem

adpct <- remove_outliers(Hahn_pct, scale_columns = c("ad_n2", "ad_n3"), memory = Hahn_beh)
Hahn_adpct_rem <- adpct$sleepchar_rem
Hahn_adbeh_rem <- adpct$memory_rem
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients for the child group in each sleep stage
cor_ch <- c(
  N2 = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chpct_rem$ch_n2, use = "complete"),
  N3 = cor(Hahn_chbeh_rem$ch_diff ~ Hahn_chpct_rem$ch_n3, use = "complete")
)

# Calculate correlation coefficients for the adolescent group in each sleep stage
cor_ad <- c(
  N2 = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adpct_rem$ad_n2, use = "complete"),
  N3 = cor(Hahn_adbeh_rem$ad_diff ~ Hahn_adpct_rem$ad_n3, use = "complete")
)

# Create the table
cortable("Hahn 2020", 4, Child = cor_ch, Adolescent = cor_ad)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Kurz2023

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Kurz 2023
Kurz2023_raw <- read_csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Kurz2023/Sourcedata/dataDRMdevelopment.csv", show_col_types = FALSE)
#> view(Kurz2023_raw)
# Exclude participants from the wake group & with missing values
Kurz2023 <- Kurz2023_raw |>
  filter(Condition == "Sleep" & rowSums(is.na(cur_data()[, 46:84])) == 0) |>
  dplyr::select(7,46:84)
view(Kurz2023)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Coupling Phase Preprocessing
## Calculate the circular linear correlation
variables <- names(Kurz2023)[35:40]
effect_size <- data.frame()
for (var in variables) {
  effect_var <- circular_cor(Kurz2023[[var]], Kurz2023$DRM_correct)
  effect_size <- rbind(effect_size, effect_var)
}
rownames(effect_size) <- c("Slow Frontal", "Slow Central", "Slow Parietal","Fast Frontal", "Fast Central", "Fast Parietal")
knitr::kable(effect_size, format = "markdown", caption = "Kurz 2023 CP Phase and Memory Circular Linear Correlation Table")
## n = 30
```

```{r}
#| warning: false
#| message: false
#| include: false
## Spindle Amplitude Preprocessing
## Detect and Remove outlier(s)
Kurz2023amp <- remove_outliers(Kurz2023, scale_columns = c("SP_amplitude_NonREM_fast_frontal", "SP_amplitude_NonREM_fast_central", "SP_amplitude_NonREM_fast_parietal","SP_amplitude_NonREM_slow_frontal", "SP_amplitude_NonREM_slow_central", "SP_amplitude_NonREM_slow_parietal"))
#> view(Kurz2023amp)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(DRM_correct ~ SP_amplitude_NonREM_fast_frontal, use = "complete", data = Kurz2023amp),
  "Central" = cor(DRM_correct ~ SP_amplitude_NonREM_fast_central, use = "complete", data = Kurz2023amp),
  "Parietal" = cor(DRM_correct ~ SP_amplitude_NonREM_fast_parietal, use = "complete", data = Kurz2023amp))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(DRM_correct ~ SP_amplitude_NonREM_slow_frontal, use = "complete", data = Kurz2023amp),
  "Central " = cor(DRM_correct ~ SP_amplitude_NonREM_slow_central, use = "complete", data = Kurz2023amp),
  "Parietal" = cor(DRM_correct ~ SP_amplitude_NonREM_slow_parietal, use = "complete", data = Kurz2023amp))

# Create the table
cortable("Kurz 2023", 2, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Strength Preprocessing
## Detect and Remove outlier(s)
Kurz2023str <- remove_outliers(Kurz2023, scale_columns = c("CouplStrengthOnlyCoupl_slow_frontal", "CouplStrengthOnlyCoupl_slow_central", "CouplStrengthOnlyCoupl_slow_parietal","CouplStrengthOnlyCoupl_fast_frontal", "CouplStrengthOnlyCoupl_fast_central", "CouplStrengthOnlyCoupl_fast_parietal"))
#> view(Kurz2023str)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast SP coupling and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_fast_frontal, use = "complete", data = Kurz2023str),
  "Central" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_fast_central, use = "complete", data = Kurz2023str),
  "Parietal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_fast_parietal, use = "complete", data = Kurz2023str))

# Calculate correlation coefficients between slow SP coupling and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_slow_frontal, use = "complete", data = Kurz2023str),
  "Central " = cor(DRM_correct ~ CouplStrengthOnlyCoupl_slow_central, use = "complete", data = Kurz2023str),
  "Parietal" = cor(DRM_correct ~ CouplStrengthOnlyCoupl_slow_parietal, use = "complete", data = Kurz2023str))

# Create the table
cortable("Kurz 2023", 3, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Donnelly2022

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Donnelly 2022
eeg_download <- "https://github.com/Theaang/so-sp-coupling/raw/main/Paper/Donnelly2022/Sourcedata/sleep_study_eeg_summary_data_z.rds"
Donnelly_eeg <- readRDS(url(eeg_download, method="libcurl"))
beh_download <- "https://github.com/Theaang/so-sp-coupling/raw/main/Paper/Donnelly2022/Sourcedata/sleep_study_beh_psych_demographic_data.rds"
Donnelly_behrow <- readRDS(url(beh_download, method="libcurl"))
#> view(Donnelly_eeg)
#> view(Donnelly_behrow)

## Extract all datasets from the RDS file
Donnelly2022 <- list()
for (i in 1:nrow(Donnelly_eeg)) {
  Donnelly2022[[i]] <- Donnelly_eeg[[3]][[i]]
}
Donnellyamp_raw <- Donnelly2022[[14]]
Donnellystr_raw <- Donnelly2022[[20]]
Donnellyphase_raw <- Donnelly2022[[21]]
## N2sigpwr <- Donnelly2022[[1]]
## N3sigpwr <- Donnelly2022[[6]]
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Transform the memory data
# Calculate the memory retention rate
# Exclude participants from the patient group and missing values
Donnelly_beh <- Donnelly_behrow |>
  filter(group == "Sib") |>
  mutate(retention = accC_morning - accC_evening) |>
  filter(rowSums(is.na(cur_data()[, 26:27])) == 0)
#> view(Donnelly_beh)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Phase Preprocessing
# Filter unused groups and electrodes
Donnellyphase <- Donnellyphase_raw |>
  filter(group == "Sib" & !grepl("^FC|^T|^FP|^FT|^CP|^AF", electrode))

# Adjust the dataframe format for data extraction
Donnellyphase <- Donnellyphase |>
  pivot_wider(names_from = electrode,
              values_from = value,
              id_cols = subject)
#> view(Donnellyphase)

# Calculate the mean coupling phase for each electrode location cluster
Donnellyphase_avg <- Donnellyphase |>
  rowwise() |>
  mutate(
    Favg = (mean(c(F3, F4, Fz)) * pi) / 180,
    Cavg = (mean(c(C3, C4, Cz)) * pi) / 180,
    POavg = (mean(c(P3, P4, Pz, O1, O2)) * pi) / 180)
Donnellyphase_avg <- Donnellyphase_avg[-7,]
#> view(Donnellyphase_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
## Calculate the circular linear correlation
variables <- c("Favg", "Cavg", "POavg")
effect_size <- data.frame()
for (var in variables) {
  effect_var <- circular_cor(Donnellyphase_avg[[var]], Donnelly_beh$retention)
  effect_size <- rbind(effect_size, effect_var)
}
rownames(effect_size) <- c("Frontal", "Central", "Parietal and Occipital")
knitr::kable(effect_size, format = "markdown", caption = "Donnelly 2022 CP Phase and Memory Circular Linear Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| include: false
## Spindle Amplitude Preprocessing
# Filter unused groups and electrodes
Donnellyamp <- Donnellyamp_raw |>
  filter(group == "Sib" & !grepl("^FC|^T|^FP|^FT|^CP|^AF", electrode))

# Adjust the dataframe format for data extraction
Donnellyamp <- Donnellyamp |>
  pivot_wider(names_from = electrode,
              values_from = value,
              id_cols = subject)
#> view(Donnellyamp)

# Calculate the mean spindle amplitude for each electrode location cluster
Donnellyamp_avg <- Donnellyamp |>
  rowwise() |>
  mutate(
    Favg = (mean(c(F3, F4, Fz))),
    Cavg = (mean(c(C3, C4, Cz))),
    POavg = (mean(c(P3, P4, Pz, O1, O2))))
Donnellyamp_avg <- Donnellyamp_avg[-7,]

# Detect and remove outlier(s)
Donnellyamp_avg <- remove_outliers(Donnellyamp_avg, scale_columns = c("Favg", "Cavg", "POavg"))
Donnelly_beh_amp <- Donnelly_beh[-3, ]
#> view(Donnellyamp_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between spindle amplitude and memory in each channel location
cor <- c(
  "Frontal" = cor(Donnelly_beh_amp$retention ~ Donnellyamp_avg$Favg, use = "complete"),
  "Central" = cor(Donnelly_beh_amp$retention ~ Donnellyamp_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Donnelly_beh_amp$retention ~ Donnellyamp_avg$POavg, use = "complete"))

cortable("Donnelly 2022", 2, "Correlation" = cor)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Strength Preprocessing
# Filter unused groups and electrodes
Donnellystr <- Donnellystr_raw |>
  filter(group == "Sib" & !grepl("^FC|^T|^FP|^FT|^CP|^AF", electrode))

# Adjust the dataframe format for data extraction
Donnellystr <- Donnellystr |>
  pivot_wider(names_from = electrode,
              values_from = value,
              id_cols = subject)
#> view(Donnellystr)

# Calculate the mean coupling strength for each electrode location cluster
Donnellystr_avg <- Donnellystr |>
  rowwise() |>
  mutate(
    Favg = (mean(c(F3, F4, Fz))),
    Cavg = (mean(c(C3, C4, Cz))),
    POavg = (mean(c(P3, P4, Pz, O1, O2))))
Donnellystr_avg <- Donnellystr_avg[-7,]

# Detect and remove outlier(s)
Donnellystr_avg <- remove_outliers(Donnellystr_avg, scale_columns = c("Favg", "Cavg", "POavg"))

#> view(Donnellystr_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between coupling strength and memory in each channel location
cor <- c(
  "Frontal" = cor(Donnelly_beh$retention ~ Donnellystr_avg$Favg, use = "complete"),
  "Central" = cor(Donnelly_beh$retention ~ Donnellystr_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(Donnelly_beh$retention ~ Donnellystr_avg$POavg, use = "complete"))

cortable("Donnelly 2022", 3, "Correlation" = cor)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Denis2022

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Denis 2022
Denis_files <- c("behaviour.csv", "fast_amplitude.csv", "slow_amplitude.csv", 
                "fast_power.csv", "slow_power.csv", "fast_consistency.csv", 
                "slow_consistency.csv", "fast_percent.csv", "slow_percent.csv", 
                "fast_phase.csv", "slow_phase.csv")
for (file in Denis_files) {
  file_url <- paste0("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Denis2022/Sourcedata/", file)
  data <- read.csv(file_url)
  data <- data[-c(18, 34), ] ## Remove empty rows
  assign(gsub(".csv", "", file), data)
}
behaviour_fast <- behaviour |>
  rowwise() |>
  mutate(
  change_pres = change_1pres)
## Create a separate behavior dataset for slow spindle data due to missing value
behaviour_slow = behaviour_fast[-c(5, 7, 12, 27, 28, 32), ]
## view(behaviour_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Coupling Phase Preprocessing
## Calculate the mean coupling phase for each electrode location cluster
fast_phase_avg <- fast_phase |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2))))
## view(fast_phase_avg)
slow_phase_avg <- slow_phase |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_phase_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
variables <- c("Favg", "Cavg", "POavg")
es_fast <- data.frame()
for (var in variables) {
ev_fast <- circular_cor(fast_phase_avg[[var]], behaviour_fast$change_pres)
es_fast <- rbind(es_fast, ev_fast)
}
es_slow <- data.frame()
for (var in variables) {
ev_slow <- circular_cor(slow_phase_avg[[var]], behaviour_slow$change_pres)
es_slow <- rbind(es_slow, ev_slow)
}
effect_size <- rbind(es_slow, es_fast)
rownames(effect_size) <- c("Slow Frontal", "Slow Central", "Slow Parietal and Occipital","Fast Frontal", "Fast Central", "Fast Parietal and Occipital")
knitr::kable(effect_size, format = "markdown", caption = "Denis 2022 CP Phase and Memory Circular Linear Correlation Table")
```

```{r}
#| warning: false
#| message: false
#| include: false
fast_amplitude_avg <- fast_amplitude |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2))))
## view(fast_amplitude_avg)
slow_amplitude_avg <- slow_amplitude |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_amplitude_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ fast_amplitude_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ fast_amplitude_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(behaviour_fast$change_pres ~ fast_amplitude_avg$POavg, use = "complete"))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(behaviour_slow$change_pres ~ slow_amplitude_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_slow$change_pres ~ slow_amplitude_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(behaviour_slow$change_pres ~ slow_amplitude_avg$POavg, use = "complete"))

# Create the table
cortable("Denis 2022", 2, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
fast_consistency_avg <- fast_consistency |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2))))
## view(fast_consistency_avg)
slow_consistency_avg <- slow_consistency |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_consistency_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ fast_consistency_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ fast_consistency_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(behaviour_fast$change_pres ~ fast_consistency_avg$POavg, use = "complete"))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(behaviour_slow$change_pres ~ slow_consistency_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_slow$change_pres ~ slow_consistency_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(behaviour_slow$change_pres ~ slow_consistency_avg$POavg, use = "complete"))

# Create the table
cortable("Denis 2022", 3, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
fast_percent_avg <- fast_percent |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2))))
## view(fast_percent_avg)
slow_percent_avg <- slow_percent |>
rowwise() |>
mutate(
 Favg = (mean(c(F3, F4, Fz))),
 Cavg = (mean(c(C3, C4, Cz))),
 POavg = (mean(c(P3, P4, Pz, O1, O2)))) |>
  filter(!any(is.na(c_across(F2:POavg))))
## view(slow_percent_avg)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate correlation coefficients between fast spindles and memory in each channel location
cor_fast <- c(
  "Frontal" = cor(behaviour_fast$change_pres ~ fast_percent_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_fast$change_pres ~ fast_percent_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(behaviour_fast$change_pres ~ fast_percent_avg$POavg, use = "complete"))

# Calculate correlation coefficients between slow spindles and memory in each channel location
cor_slow <- c(
  "Frontal" = cor(behaviour_slow$change_pres ~ slow_percent_avg$Favg, use = "complete"),
  "Central" = cor(behaviour_slow$change_pres ~ slow_percent_avg$Cavg, use = "complete"),
  "Parietal and Occipital" = cor(behaviour_slow$change_pres ~ slow_percent_avg$POavg, use = "complete"))

# Create the table
cortable("Denis 2022", 4, flip = FALSE, "Fast Spindle" = cor_fast, "Slow Spindle" = cor_slow)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Mylonas2020

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Mylonas2020
Mylonas2020 <- read.csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Mylonas2020/Sourcedata/Mylonas2020data.csv")
Mylonas2020 <- Mylonas2020[-29, ]
Mylonas2020cp <- Mylonas2020[-22, ]
#> view(Mylonas2020)
#> view(Mylonas2020cp)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate the circular linear correlation
mylonas_phase <- circular_cor(Mylonas2020cp$Preferred.Phase..degrees., Mylonas2020cp$Memory.Change....)
## knitr::kable(sch_phase,format ="markdown",caption ="Mylonas 2020 CP Phase and Memory Circular Linear Correlation Table",row.names = FALSE)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate the coupling percentage and remove outlier(s)
Mylonas2020amp <- remove_outliers(Mylonas2020, scale_columns = "Spindle.Amplitude..muV.")
Mylonas2020str <- remove_outliers(Mylonas2020cp, scale_columns = "Coupling.Strength")
Mylonas2020pct <- remove_outliers(Mylonas2020, scale_columns =  c("X..of.Spindles.Coupled.to.SOs","X..of.SOs.coupled.to.spindles"))
```

```{r}
#| warning: false
#| message: false
#| include: false
cor1 <- cor(Spindle.Amplitude..muV. ~ Memory.Change...., use = "complete", data = Mylonas2020amp)
## cortable("Mylonas 2020", 2, flip = FALSE, "Correlation" = cor1)
cor2 <- cor(Coupling.Strength ~ Memory.Change...., use = "complete", data = Mylonas2020str)
## cortable("Mylonas 2020", 3, flip = FALSE, "Correlation" = cor2)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Calculate the linear correlation between SO coupled SP and memory retention
cor3 <- cor(X..of.Spindles.Coupled.to.SOs ~ Memory.Change...., use = "complete", data = Mylonas2020pct)
## Calculate the linear correlation between SP coupled SO and memory retention
cor4 <- cor(X..of.SOs.coupled.to.spindles ~ Memory.Change...., use = "complete", data = Mylonas2020pct)
## cortable("Mylonas 2020", 4, flip = FALSE, "SPcSO" = cor3, "SOcSP" = cor4)
```

```{r}
#| warning: false
#| message: false
#| echo: false
effect_size <- rbind(mylonas_phase, cor1, cor2, cor3, cor4)
knitr::kable(data.frame("Phase" = mylonas_phase, "Amplitude" = cor1, "Strength" = cor2, "SPcSO" = cor3, "SOcSP" = cor4), format = "markdown", caption = "Mylonas 2020 Coupling and Memory Correlation Table", row.names = FALSE)
```

```{r}
#| warning: false
#| message: false
#| include: false
## Remove all unused variables
rm(list = ls())
load("preprocessing_fun.RData")
```

## Hahn2022

```{r}
#| warning: false
#| message: false
#| include: false
## Import source data from Hahn2022
Hahn_phasead <- read.csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2022/Sourcedata/phase_adolescent.csv")
Hahn_phaseya <- read.csv("https://raw.githubusercontent.com/Theaang/so-sp-coupling/main/Paper/Hahn2022/Sourcedata/phase_adult.csv")
view(Hahn_phasead)
```

```{r}
#| warning: false
#| message: false
#| echo: false
cor_ad <- c(
  Frontal = mean(Hahn_phasead$rho_baseskillchange[Hahn_phasead$Electrode %in% c("F3", "F4", "Fz")]),
  Central = mean(Hahn_phasead$rho_baseskillchange[Hahn_phasead$Electrode %in% c("C3", "C4", "Cz")]),
  "Parietal and Occipital" = mean(Hahn_phasead$rho_baseskillchange[Hahn_phasead$Electrode %in% c("P3", "P4", "Pz", "O1", "O2")])
)

cor_ya <- c(
  Frontal = mean(Hahn_phaseya$rho_baseskillchange[Hahn_phaseya$Electrode %in% c("F3", "F4", "Fz")]),
  Central = mean(Hahn_phaseya$rho_baseskillchange[Hahn_phaseya$Electrode %in% c("C3", "C4", "Cz")]),
  "Parietal and Occipital" = mean(Hahn_phaseya$rho_baseskillchange[Hahn_phaseya$Electrode %in% c("P3", "P4", "Pz", "O1", "O2")])
)
effect_size <- data.frame("Adolescent" = cor_ad, "Young Adult" = cor_ya)
knitr::kable(effect_size, format = "markdown", caption = "Hahn 2022 CP Phase and Memory Circular Linear Correlation Table")
```

# IV. References

1.  Mardia, K. V. (1976). Linear-Circular Correlation Coefficients and Rhythmometry. *Biometrika,* 63(2), 403--405. <https://doi.org/10.2307/2335637>

2.  Posit Team (2023). RStudio: Integrated Development for R. *Posit Software, PBC, Boston, MA. *<http://www.rstudio.com/>.

3.  R Core Team (2022). R: A language and environment for statistical computing. *R Foundation for Statistical Computing, Vienna, Austria.* <https://www.R-project.org/>.
